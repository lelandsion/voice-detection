{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78edeb5",
   "metadata": {},
   "source": [
    "# Voice Input Pipeline (PI1–PI5)\n",
    "\n",
    "This notebook implements the microphone recording pipeline requirements with explicit sections:\n",
    "\n",
    "- **PI1 (Basic):** Capture audio and save in a standard format (`.wav`)\n",
    "- **PI2 (Basic):** Start/stop recording UI\n",
    "- **PI3 (Expected):** Real-time audio level monitoring + quality feedback\n",
    "- **PI4 (Expected):** Save metadata (timestamp, duration, sample rate, path)\n",
    "- **PI5 (Advanced):** Automated preprocessing (noise reduction + normalization)\n",
    "\n",
    "> If a package is missing, install it in your environment (examples in next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9659e823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 Microphone Array (Intel® Smart , MME (4 in, 0 out)\n",
      "   2 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  3 LG FULL HD (NVIDIA High Definit, MME (0 in, 2 out)\n",
      "   4 Speakers (Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   5 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   6 Microphone Array (Intel® Smart Sound Technology for Digital Microphones), Windows DirectSound (4 in, 0 out)\n",
      "   7 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "   8 LG FULL HD (NVIDIA High Definition Audio), Windows DirectSound (0 in, 2 out)\n",
      "   9 Speakers (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "  10 Speakers (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  11 LG FULL HD (NVIDIA High Definition Audio), Windows WASAPI (0 in, 2 out)\n",
      "  12 Microphone Array (Intel® Smart Sound Technology for Digital Microphones), Windows WASAPI (2 in, 0 out)\n",
      "  13 Microphone Array 1 (), Windows WDM-KS (2 in, 0 out)\n",
      "  14 Microphone Array 2 (), Windows WDM-KS (2 in, 0 out)\n",
      "  15 Microphone Array 3 (), Windows WDM-KS (4 in, 0 out)\n",
      "  16 Input 1 (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (1 in, 0 out)\n",
      "  17 Input 2 (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (1 in, 0 out)\n",
      "  18 Output 1 (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (0 in, 1 out)\n",
      "  19 Output 2 (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (0 in, 8 out)\n",
      "  20 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (1 in, 0 out)\n",
      "  21 Output 3 (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Liams iphone)), Windows WDM-KS (0 in, 1 out)\n",
      "  22 Output (NVIDIA High Definition Audio), Windows WDM-KS (0 in, 2 out)\n",
      "  23 Stereo Mix (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  24 Headphones 1 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  25 Headphones 2 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  26 PC Speaker (Realtek HD Audio 2nd output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  27 Speakers 1 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  28 Speakers 2 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  29 PC Speaker (Realtek HD Audio output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  30 Microphone (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  31 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  32 Input (), Windows WDM-KS (2 in, 0 out)\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# PI1–PI5 imports and setup\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sounddevice as sd\n",
    "# print(sd.query_devices()) # Uncomment the above line to see the list of audio devices and find the correct index for your microphone input if you have multiple devices.\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "RECORDINGS_DIR = Path(\"data/raw/recordings\")\n",
    "PROCESSED_DIR = Path(\"data/processed/recordings\")\n",
    "METADATA_CSV = Path(\"data/processed/recordings_metadata.csv\")\n",
    "RECORDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METADATA_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "state = {\n",
    "    \"is_recording\": False,\n",
    "    \"stream\": None,\n",
    "    \"frames\": [],\n",
    "    \"started_at\": None,\n",
    "    \"latest_raw_path\": None,\n",
    "    \"latest_processed_path\": None,\n",
    "    \"latest_duration_sec\": 0.0,\n",
    "    \"latest_level\": 0.0,\n",
    "}\n",
    "# MIC_DEVICE_INDEX = <your device index>  # Replace with the correct index # If you have multiple audio input devices, set this to the index of the one you want to use. You can find the index from the output of `sd.query_devices()`.\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961fa0f",
   "metadata": {},
   "source": [
    "## PI1 (Basic): Capture audio from microphone and save in standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b6b768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI1: Capture audio and save in standard format (.wav)\n",
    "def save_wav(audio_float32: np.ndarray, sample_rate: int, out_path: Path) -> Path:\n",
    "    audio_clipped = np.clip(audio_float32, -1.0, 1.0)\n",
    "    audio_int16 = (audio_clipped * 32767).astype(np.int16)\n",
    "    wav_write(str(out_path), sample_rate, audio_int16)\n",
    "    return out_path\n",
    "\n",
    "def record_fixed_duration(seconds: float = 3.0, sample_rate: int = SAMPLE_RATE, channels: int = CHANNELS) -> Path:\n",
    "    print(f\"Recording for {seconds:.1f}s...\")\n",
    "    recording = sd.rec(int(seconds * sample_rate), samplerate=sample_rate, channels=channels, dtype=\"float32\")\n",
    "    # recording = sd.rec(int(seconds * sample_rate), samplerate=sample_rate, channels=channels, dtype=\"float32\", device=MIC_DEVICE_INDEX) # Uncomment this line and set MIC_DEVICE_INDEX if you have multiple audio input devices and want to specify which one to use.\n",
    "    sd.wait()\n",
    "    if channels == 1:\n",
    "        recording = recording[:, 0]\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RECORDINGS_DIR / f\"mic_capture_{timestamp}.wav\"\n",
    "    save_wav(recording, sample_rate, out_path)\n",
    "\n",
    "    state[\"latest_raw_path\"] = str(out_path)\n",
    "    state[\"latest_duration_sec\"] = float(seconds)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cfdbac",
   "metadata": {},
   "source": [
    "## PI2 (Basic): Simple UI for start/stop recording\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574c8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9d7f4e8e1244ab86247511746d3a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Microphone Recorder</h4>'), HBox(children=(Button(button_style='success', descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PI2: Simple UI for start/stop recording\n",
    "status_label = widgets.HTML(value=\"<b>Status:</b> Idle\")\n",
    "level_bar = widgets.FloatProgress(value=0.0, min=0.0, max=0.2, description=\"Level\", bar_style=\"\")\n",
    "quality_label = widgets.HTML(value=\"<b>Quality:</b> N/A\")\n",
    "start_button = widgets.Button(description=\"Start Recording\", button_style=\"success\")\n",
    "stop_button = widgets.Button(description=\"Stop Recording\", button_style=\"danger\", disabled=True)\n",
    "out = widgets.Output()\n",
    "\n",
    "def rms_level(x: np.ndarray) -> float:\n",
    "    if x.size == 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(np.mean(np.square(x))))\n",
    "\n",
    "def level_to_quality(level: float) -> str:\n",
    "    if level < 0.01:\n",
    "        return \"Too quiet\"\n",
    "    if level < 0.04:\n",
    "        return \"Good\"\n",
    "    if level < 0.12:\n",
    "        return \"Loud\"\n",
    "    return \"Very loud / possible clipping\"\n",
    "\n",
    "def _audio_callback(indata, frames, time, status):\n",
    "    chunk = indata.copy()\n",
    "    if CHANNELS == 1:\n",
    "        chunk = chunk[:, 0]\n",
    "    state[\"frames\"].append(chunk)\n",
    "    state[\"latest_level\"] = rms_level(chunk)\n",
    "\n",
    "import time\n",
    "\n",
    "def poll_ui_updates(interval=0.1):\n",
    "    while state[\"is_recording\"]:\n",
    "        level_bar.value = min(state[\"latest_level\"], level_bar.max)\n",
    "        quality_label.value = f\"<b>Quality:</b> {level_to_quality(state['latest_level'])}\"\n",
    "        time.sleep(interval)\n",
    "\n",
    "def start_recording(_):\n",
    "    if state[\"is_recording\"]:\n",
    "        return\n",
    "    state[\"frames\"] = []\n",
    "    state[\"started_at\"] = datetime.now()\n",
    "    state[\"is_recording\"] = True\n",
    "    stream = sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=\"float32\", callback=_audio_callback)\n",
    "    # stream = sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=\"float32\", callback=_audio_callback, device=MIC_DEVICE_INDEX) # Uncomment this line and set MIC_DEVICE_INDEX if you have multiple audio input devices and want to specify which one to use.\n",
    "    stream.start()\n",
    "    state[\"stream\"] = stream\n",
    "    status_label.value = \"<b>Status:</b> Recording...\"\n",
    "    start_button.disabled = True\n",
    "    stop_button.disabled = False\n",
    "\n",
    "def stop_recording(_):\n",
    "    if not state[\"is_recording\"]:\n",
    "        return\n",
    "    stream = state[\"stream\"]\n",
    "    if stream is not None:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "    state[\"stream\"] = None\n",
    "    state[\"is_recording\"] = False\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    frames = state[\"frames\"]\n",
    "    if len(frames) == 0:\n",
    "        status_label.value = \"<b>Status:</b> No audio captured\"\n",
    "        return\n",
    "    audio = np.concatenate(frames)\n",
    "    duration_sec = len(audio) / SAMPLE_RATE\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RECORDINGS_DIR / f\"mic_capture_ui_{timestamp}.wav\"\n",
    "    save_wav(audio, SAMPLE_RATE, out_path)\n",
    "    state[\"latest_raw_path\"] = str(out_path)\n",
    "    state[\"latest_duration_sec\"] = float(duration_sec)\n",
    "    status_label.value = f\"<b>Status:</b> Saved {out_path.name} ({duration_sec:.2f}s)\"\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Saved raw audio: {out_path}\")\n",
    "\n",
    "start_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "display(widgets.VBox([widgets.HTML(\"<h4>Microphone Recorder</h4>\"), widgets.HBox([start_button, stop_button]), status_label, level_bar, quality_label, out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126252ac",
   "metadata": {},
   "source": [
    "## PI3 (Expected): Real-time audio level monitoring and recording-quality feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eef6b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI3: Real-time audio level monitoring and quality feedback\n",
    "# (Handled in PI2 UI: level_bar and quality_label update in _audio_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922401f0",
   "metadata": {},
   "source": [
    "## PI4 (Expected): Save metadata (timestamp, duration, sample rate, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31f14e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI4: Save metadata (timestamp, duration, sample rate, path)\n",
    "def save_metadata(timestamp: str, duration: float, sample_rate: int, path: str):\n",
    "    row = {\"timestamp\": timestamp, \"duration\": duration, \"sample_rate\": sample_rate, \"path\": path}\n",
    "    if METADATA_CSV.exists():\n",
    "        df = pd.read_csv(METADATA_CSV)\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame([row])\n",
    "    df.to_csv(METADATA_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dad5d",
   "metadata": {},
   "source": [
    "## PI5 (Advanced): Automated preprocessing (noise reduction + normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a147605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI5: Automated preprocessing (noise reduction + normalization)\n",
    "def preprocess_audio(audio: np.ndarray, sample_rate: int) -> np.ndarray:\n",
    "    # Simple noise reduction: estimate noise from first 0.5s, apply spectral gating\n",
    "    noise_len = min(int(sample_rate * 0.5), len(audio))\n",
    "    noise_clip = audio[:noise_len]\n",
    "    noise_std = np.std(noise_clip)\n",
    "    threshold = noise_std * 1.5\n",
    "    reduced = np.where(np.abs(audio) < threshold, 0, audio)\n",
    "    # Normalization\n",
    "    normed = reduced / (np.max(np.abs(reduced)) + 1e-8)\n",
    "    return normed.astype(np.float32)\n",
    "\n",
    "# Example usage:\n",
    "def record_and_preprocess(seconds: float = 3.0):\n",
    "    print(f\"Recording for {seconds:.1f}s...\")\n",
    "    recording = sd.rec(int(seconds * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=\"float32\")\n",
    "    sd.wait()\n",
    "    if CHANNELS == 1:\n",
    "        recording = recording[:, 0]\n",
    "    processed = preprocess_audio(recording, SAMPLE_RATE)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RECORDINGS_DIR / f\"mic_processed_{timestamp}.wav\"\n",
    "    save_wav(processed, SAMPLE_RATE, out_path)\n",
    "    save_metadata(timestamp, seconds, SAMPLE_RATE, str(out_path))\n",
    "    print(f\"Saved processed audio: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
