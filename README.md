# music-singer-recognition

Detect whether recorded audio is human or AI-generated and, for human vocals, recognize the artist/singer.

## Project Focus
- Build a centralized classification pipeline for audio deepfake detection and singer identification.
- Target use case: flag synthetic vocals and attribute genuine recordings to known artists.
- Skills welcomed: audio feature engineering, deep learning for audio, Python-based data science.

## Datasets
- Deepfake Detection Challenge (DFDC): https://ai.meta.com/datasets/dfdc/
- Kaggle Deepfake Detection Challenge: https://www.kaggle.com/c/deepfake-detection-challenge
- LJ Speech: https://keithito.com/LJ-Speech-Dataset/
- WaveFake (synthetic speech) via Zenodo: https://zenodo.org/records/5642694

## Reference Code and Resources
- WaveFake baseline: https://github.com/RUB-SysSec/WaveFake
- Audio deepfake detection examples: https://github.com/MarkHershey/AudioDeepFakeDetection?tab=readme-ov-file

## Papers and Background Reading
- Khalid, Hasam, et al. "FakeAVCeleb: A novel audio-video multimodal deepfake dataset." arXiv:2108.05080 (2021).
- Wijethunga, R. L. M. A. P. C., et al. "Deepfake audio detection: a deep learning based solution for group conversations." ICAC 2020.
- Khanjani, Zahra, Gabrielle Watson, and Vandana P. Janeja. "How deep are the fakes? focusing on audio deepfake: A survey." arXiv:2111.14203 (2021).
- Hamza, Ameer, et al. "Deepfake audio detection via MFCC features using machine learning." IEEE Access 10 (2022): 134018-134028.

## Contacts
- Originator: Brandon (brandonrogers@uvic.ca)
- Potential collaborators: Owen Lutwyche (owenoel333@gmail.com), Carter Conboy (carterconboy@uvic.ca)